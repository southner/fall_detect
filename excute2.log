nohup: 忽略输入
/home/zhang_t/workspace/southner/model/ResAttentionNet.py:252: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  fall_res[:,:,[6,7]] = self.softmax(fall_res[:,:,[6,7]])
/home/zhang_t/workspace/southner/utils/utils.py:103: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  noo_pred_c = noo_pred[noo_pred_mask]
/home/zhang_t/workspace/southner/utils/utils.py:104: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  noo_target_c = noo_target[noo_pred_mask]
/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
/home/zhang_t/workspace/southner/utils/utils.py:133: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  box_pred_response = box_pred[coo_response_mask].view(-1,3)
/home/zhang_t/workspace/southner/utils/utils.py:134: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  box_target_response = box_target[coo_response_mask].view(-1,3)
/home/zhang_t/workspace/southner/utils/utils.py:140: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  box_pred_not_response = box_pred[coo_not_response_mask].view(-1,3)
/home/zhang_t/workspace/southner/utils/utils.py:141: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  box_target_not_response = box_target[coo_not_response_mask].view(-1,3)
/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/zhang_t/workspace/southner/show_res.py:22: RuntimeWarning: divide by zero encountered in log
  return (np.log(data))/(max_val+1)*255
epoch:000 || batch 000 with loss:357.774963 
epoch:000 || batch 010 with loss:299.768860 
epoch:000 || batch 020 with loss:222.511032 
epoch:000 || batch 030 with loss:180.399323 
epoch:000 || batch 040 with loss:141.570999 
epoch:000 || batch 050 with loss:123.323364 
epoch:000 || batch 060 with loss:102.988968 
epoch:000 || batch 070 with loss: 88.394371 
epoch:000 || batch 080 with loss: 78.021622 
epoch:000 || batch 090 with loss: 73.601196 
epoch:000 || batch 100 with loss: 59.624485 
epoch:000 || batch 110 with loss: 65.091553 
epoch:000 || batch 120 with loss: 61.901836 
epoch:000 || batch 130 with loss: 59.075832 
epoch:000 || batch 140 with loss: 55.228237 
epoch:000 || batch 150 with loss: 59.654358 
epoch:000 || batch 160 with loss: 53.429001 
epoch:000 || batch 170 with loss: 55.982426 
epoch:000 || batch 180 with loss: 51.725941 
epoch:000 || batch 190 with loss: 58.851982 
epoch:000 || batch 200 with loss: 53.373329 
epoch:000 || batch 210 with loss: 59.175617 
epoch:000 || batch 220 with loss: 58.372021 
epoch:000 || batch 230 with loss: 52.907211 
epoch:000 || batch 240 with loss: 61.280640 
epoch:000 || batch 250 with loss: 55.497818 
epoch:000 || batch 260 with loss: 56.210209 
epoch:000 || batch 270 with loss: 55.697411 
epoch:000 || batch 280 with loss: 56.091713 
epoch:000 || batch 290 with loss: 56.172295 
epoch:000 || batch 300 with loss: 51.908051 
epoch:000 || batch 310 with loss: 58.075436 
epoch:000 || batch 320 with loss: 51.124977 
epoch:000 || batch 330 with loss: 50.851944 
epoch:000 || batch 340 with loss: 57.391319 
epoch:000 || batch 350 with loss: 55.527020 
epoch:000 || batch 360 with loss: 60.465469 
epoch:000 || batch 370 with loss: 61.750755 
epoch:000 || batch 380 with loss: 56.259598 
epoch:001 || batch 000 with loss: 52.064217 
epoch:001 || batch 010 with loss: 55.044720 
epoch:001 || batch 020 with loss: 60.902851 
epoch:001 || batch 030 with loss: 53.625816 
epoch:001 || batch 040 with loss: 55.584351 
epoch:001 || batch 050 with loss: 55.659286 
epoch:001 || batch 060 with loss: 57.238644 
epoch:001 || batch 070 with loss: 51.370750 
epoch:001 || batch 080 with loss: 51.437954 
epoch:001 || batch 090 with loss: 54.802406 
epoch:001 || batch 100 with loss: 49.871319 
epoch:001 || batch 110 with loss: 61.917118 
epoch:001 || batch 120 with loss: 52.633137 
epoch:001 || batch 130 with loss: 53.597206 
epoch:001 || batch 140 with loss: 58.471199 
epoch:001 || batch 150 with loss: 58.032776 
epoch:001 || batch 160 with loss: 49.860100 
epoch:001 || batch 170 with loss: 50.710732 
epoch:001 || batch 180 with loss: 59.999512 
epoch:001 || batch 190 with loss: 57.286018 
epoch:001 || batch 200 with loss: 58.389053 
epoch:001 || batch 210 with loss: 55.774467 
epoch:001 || batch 220 with loss: 57.320099 
epoch:001 || batch 230 with loss: 54.021362 
epoch:001 || batch 240 with loss: 59.262787 
epoch:001 || batch 250 with loss: 53.896027 
epoch:001 || batch 260 with loss: 54.576756 
epoch:001 || batch 270 with loss: 58.951073 
epoch:001 || batch 280 with loss: 49.583351 
epoch:001 || batch 290 with loss: 56.973103 
epoch:001 || batch 300 with loss: 53.256401 
epoch:001 || batch 310 with loss: 57.768234 
epoch:001 || batch 320 with loss: 56.532570 
epoch:001 || batch 330 with loss: 55.380905 
epoch:001 || batch 340 with loss: 56.725544 
epoch:001 || batch 350 with loss: 56.116585 
epoch:001 || batch 360 with loss: 57.170525 
epoch:001 || batch 370 with loss: 53.162174 
epoch:001 || batch 380 with loss: 53.092850 
/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: Error detected in MseLossBackward0. Traceback of forward call that caused the error:
  File "/home/zhang_t/workspace/southner/train.py", line 174, in <module>
    main()
  File "/home/zhang_t/workspace/southner/train.py", line 81, in main
    train(e, model, train_data_loader, criterion, optimizer)
  File "/home/zhang_t/workspace/southner/train.py", line 111, in train
    loss = criterion(predict, tag)
  File "/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zhang_t/workspace/southner/utils/utils.py", line 146, in forward
    class_loss = F.mse_loss(class_pred,class_target,size_average=False)
  File "/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/nn/functional.py", line 3292, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
  File "/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/fx/traceback.py", line 57, in format_stack
    return traceback.format_stack()
 (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/python_anomaly_mode.cpp:114.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
epoch:002 || batch 000 with loss: 55.818020 
epoch:002 || batch 010 with loss: 60.872391 
epoch:002 || batch 020 with loss: 55.008911 
epoch:002 || batch 030 with loss: 54.783363 
epoch:002 || batch 040 with loss: 58.615005 
epoch:002 || batch 050 with loss: 54.045475 
epoch:002 || batch 060 with loss: 56.030373 
epoch:002 || batch 070 with loss: 59.891785 
epoch:002 || batch 080 with loss: 55.958046 
epoch:002 || batch 090 with loss: 53.029030 
epoch:002 || batch 100 with loss: 56.655418 
epoch:002 || batch 110 with loss: 53.498444 
epoch:002 || batch 120 with loss: 50.200832 
epoch:002 || batch 130 with loss: 53.172676 
epoch:002 || batch 140 with loss: 58.517017 
epoch:002 || batch 150 with loss: 53.445156 
epoch:002 || batch 160 with loss: 53.320854 
epoch:002 || batch 170 with loss: 55.791882 
epoch:002 || batch 180 with loss: 59.934853 
epoch:002 || batch 190 with loss: 57.557587 
epoch:002 || batch 200 with loss: 53.490982 
epoch:002 || batch 210 with loss: 56.042225 
epoch:002 || batch 220 with loss: 53.665447 
epoch:002 || batch 230 with loss: 46.778229 
epoch:002 || batch 240 with loss: 62.531487 
epoch:002 || batch 250 with loss: 54.734505 
epoch:002 || batch 260 with loss: 54.262951 
epoch:002 || batch 270 with loss: 56.080872 
epoch:002 || batch 280 with loss: 57.021164 
epoch:002 || batch 290 with loss: 54.097363 
epoch:002 || batch 300 with loss: 53.217598 
epoch:002 || batch 310 with loss: 51.603405 
epoch:002 || batch 320 with loss: 54.091438 
epoch:002 || batch 330 with loss: 52.002766 
epoch:002 || batch 340 with loss: 55.031120 
epoch:002 || batch 350 with loss: 54.143879 
Traceback (most recent call last):
  File "/home/zhang_t/workspace/southner/train.py", line 174, in <module>
    main()
  File "/home/zhang_t/workspace/southner/train.py", line 81, in main
    train(e, model, train_data_loader, criterion, optimizer)
  File "/home/zhang_t/workspace/southner/train.py", line 114, in train
    loss.backward()
  File "/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/zhang_t/.conda/envs/mmwave/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Function 'MseLossBackward0' returned nan values in its 0th output.
